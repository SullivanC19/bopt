(3196, 73) (3196,)
{0, 1}

dl85 depth=1
train_accs: [0.72378717 0.70629644 0.70355886 0.68713336 0.76378569] 0.7169123024769222
test_fold: [0.521875   0.47730829 0.59780908 0.55399061 0.36150235] 0.5024970657276995

cart depth=1
train_accs: [0.70618153 0.70629644 0.70355886 0.68713336 0.76378569] 0.7133911757163587
test_fold: [0.478125   0.47730829 0.59780908 0.55399061 0.36150235] 0.49374706572769955


lpdl85 depth=1
best params:{'regulator': 0.1}
train_acc for fold0=0.9663536776212832
test_acc for fold0=0.8515625
n_trees for fold0=5

best params:{'regulator': 0.7}
train_acc for fold1=0.980054751662104
test_acc for fold1=0.9593114241001565
n_trees for fold1=24

best params:{'regulator': 0.7}
train_acc for fold2=0.9726241689479859
test_acc for fold2=0.97339593114241
n_trees for fold2=15

best params:{'regulator': 0.1}
train_acc for fold3=0.9507235041063746
test_acc for fold3=0.8967136150234741
n_trees for fold3=6

best params:{'regulator': 0.1}
train_acc for fold4=0.938991005084083
test_acc for fold4=0.8841940532081377
n_trees for fold4=12

n_trees: [5, 24, 15, 6, 12] 12.4
train_accs: [0.9663536776212832, 0.980054751662104, 0.9726241689479859, 0.9507235041063746, 0.938991005084083] 0.9617494214843662
test_accs: [0.8515625, 0.9593114241001565, 0.97339593114241, 0.8967136150234741, 0.8841940532081377] 0.9130355046948356
regulator: [0.1, 0.7, 0.7, 0.1, 0.1]


AdaBoost non-linear max_trees
n_trees: [12, 12, 12, 12, 12] 12.0
train_accs: [0.96126761 0.95385217 0.948377   0.95228784 0.95150567] 0.9534580576930491
test_accs: [0.853125   0.96087637 0.97339593 0.92488263 0.88888889] 0.9202337636932707


AdaBoost non-linear
best params:{'n_estimators': 100}
train_acc for fold0=0.9835680751173709
test_acc for fold0=0.8453125
n_trees for fold0=100

best params:{'n_estimators': 1000}
train_acc for fold1=0.9722330856472429
test_acc for fold1=0.9546165884194053
n_trees for fold1=1000

best params:{'n_estimators': 100}
train_acc for fold2=0.9679311693390692
test_acc for fold2=0.971830985915493
n_trees for fold2=100

best params:{'n_estimators': 100}
train_acc for fold3=0.9788815017598749
test_acc for fold3=0.9530516431924883
n_trees for fold3=100

best params:{'n_estimators': 50}
train_acc for fold4=0.965975752835354
test_acc for fold4=0.9264475743348983
n_trees for fold4=50

n_trees: [100, 1000, 100, 100, 50] 270.0
train_accs: [0.9835680751173709, 0.9722330856472429, 0.9679311693390692, 0.9788815017598749, 0.965975752835354] 0.9737179169397823
test_accs: [0.8453125, 0.9546165884194053, 0.971830985915493, 0.9530516431924883, 0.9264475743348983] 0.930251858372457


XGBoost non-linear maxtrees
best params:{'objective': 'binary:logistic'}
train_acc for fold0=0.9632237871674492
test_acc for fold0=0.8515625
n_trees for fold0=12

best params:{'objective': 'binary:logistic'}
train_acc for fold1=0.9350801720766523
test_acc for fold1=0.9640062597809077
n_trees for fold1=12

best params:{'objective': 'binary:logistic'}
train_acc for fold2=0.9276495893625342
test_acc for fold2=0.9937402190923318
n_trees for fold2=12

best params:{'objective': 'binary:logistic'}
train_acc for fold3=0.9452483378959718
test_acc for fold3=0.9233176838810642
n_trees for fold3=12

best params:{'objective': 'binary:logistic'}
train_acc for fold4=0.9049667579194368
test_acc for fold4=0.8888888888888888
n_trees for fold4=12

n_trees: [12, 12, 12, 12, 12] 12.0
train_accs: [0.9632237871674492, 0.9350801720766523, 0.9276495893625342, 0.9452483378959718, 0.9049667579194368] 0.9352337288844088
test_accs: [0.8515625, 0.9640062597809077, 0.9937402190923318, 0.9233176838810642, 0.8888888888888888] 0.9243031103286384
objective: ['binary:logistic', 'binary:logistic', 'binary:logistic', 'binary:logistic', 'binary:logistic']


XGBoost non-linear
best params:{'n_estimators': 50, 'objective': 'binary:logitraw'}
train_acc for fold0=0.960093896713615
test_acc for fold0=0.8515625
n_trees for fold0=50

best params:{'n_estimators': 1000, 'objective': 'binary:logitraw'}
train_acc for fold1=0.9757528353539304
test_acc for fold1=0.9405320813771518
n_trees for fold1=1000

best params:{'n_estimators': 100, 'objective': 'binary:logistic'}
train_acc for fold2=0.9456394211967148
test_acc for fold2=0.97339593114241
n_trees for fold2=100

best params:{'n_estimators': 100, 'objective': 'binary:logistic'}
train_acc for fold3=0.9511145874071177
test_acc for fold3=0.9092331768388107
n_trees for fold3=100

best params:{'n_estimators': 100, 'objective': 'binary:logistic'}
train_acc for fold4=0.939382088384826
test_acc for fold4=0.94679186228482
n_trees for fold4=100

n_trees: [50, 1000, 100, 100, 100] 270.0
train_accs: [0.960093896713615, 0.9757528353539304, 0.9456394211967148, 0.9511145874071177, 0.939382088384826] 0.9543965658112408
test_accs: [0.8515625, 0.9405320813771518, 0.97339593114241, 0.9092331768388107, 0.94679186228482] 0.9243031103286384
objective: ['binary:logitraw', 'binary:logitraw', 'binary:logistic', 'binary:logistic', 'binary:logistic']


RF non-linear maxtrees
n_trees: [12, 12, 12, 12, 12] 12.0
train_accs: [0.79733959 0.8384826  0.79468127 0.93390692 0.81892843] 0.836667762189528
test_accs: [0.5359375  0.74178404 0.69014085 0.8372457  0.57120501] 0.675262617370892


RF non-linear
best params:{'n_estimators': 1000}
train_acc for fold0=0.8438967136150235
test_acc for fold0=0.6078125
n_trees for fold0=1000

best params:{'n_estimators': 100}
train_acc for fold1=0.8435666797027767
test_acc for fold1=0.809076682316119
n_trees for fold1=100

best params:{'n_estimators': 1000}
train_acc for fold2=0.8768087602659367
test_acc for fold2=0.9436619718309859
n_trees for fold2=1000

best params:{'n_estimators': 100}
train_acc for fold3=0.9350801720766523
test_acc for fold3=0.8450704225352113
n_trees for fold3=100

best params:{'n_estimators': 50}
train_acc for fold4=0.8220570981619085
test_acc for fold4=0.6025039123630673
n_trees for fold4=50

n_trees: [1000, 100, 1000, 100, 50] 450.0
train_accs: [0.8438967136150235, 0.8435666797027767, 0.8768087602659367, 0.9350801720766523, 0.8220570981619085] 0.8642818847644594
test_accs: [0.6078125, 0.809076682316119, 0.9436619718309859, 0.8450704225352113, 0.6025039123630673] 0.7616250978090766


GB non-linear maxtrees
n_trees: [12, 12, 12, 12, 12] 12.0
train_accs: [0.81298905 0.70629644 0.79468127 0.91904576 0.7938991 ] 0.8053823221779728
test_accs: [0.521875   0.47730829 0.70892019 0.84507042 0.41627543] 0.5938898669796557


GB non-linear
best params:{'n_estimators': 1000}
train_acc for fold0=0.9761345852895149
test_acc for fold0=0.8546875
n_trees for fold0=1000

best params:{'n_estimators': 1000}
train_acc for fold1=0.9687133359405553
test_acc for fold1=0.9608763693270735
n_trees for fold1=1000

best params:{'n_estimators': 1000}
train_acc for fold2=0.9632381697301525
test_acc for fold2=0.9765258215962441
n_trees for fold2=1000

best params:{'n_estimators': 1000}
train_acc for fold3=0.9702776691435275
test_acc for fold3=0.9311424100156495
n_trees for fold3=1000

best params:{'n_estimators': 1000}
train_acc for fold4=0.9648025029331248
test_acc for fold4=0.9405320813771518
n_trees for fold4=1000

n_trees: [1000, 1000, 1000, 1000, 1000] 1000.0
train_accs: [0.9761345852895149, 0.9687133359405553, 0.9632381697301525, 0.9702776691435275, 0.9648025029331248] 0.968633252607375
test_accs: [0.8546875, 0.9608763693270735, 0.9765258215962441, 0.9311424100156495, 0.9405320813771518] 0.9327528364632236


SVM linear
best params:{'C': 0.1, 'kernel': 'linear'}
train_acc for fold0=0.9632237871674492
test_acc for fold0=0.8515625
best params:{'C': 1, 'kernel': 'linear'}
train_acc for fold1=0.9765350019554165
test_acc for fold1=0.9608763693270735
best params:{'C': 1, 'kernel': 'linear'}
train_acc for fold2=0.9718420023464998
test_acc for fold2=0.9765258215962441
best params:{'C': 1, 'kernel': 'linear'}
train_acc for fold3=0.9769260852561595
test_acc for fold3=0.9295774647887324
best params:{'C': 1, 'kernel': 'linear'}
train_acc for fold4=0.9632381697301525
test_acc for fold4=0.92018779342723
train_accs: [0.9632237871674492, 0.9765350019554165, 0.9718420023464998, 0.9769260852561595, 0.9632381697301525] 0.9703530092911355
test_accs: [0.8515625, 0.9608763693270735, 0.9765258215962441, 0.9295774647887324, 0.92018779342723] 0.9277459898278562


SVM non-linear
best params:{'C': 1000, 'degree': 2, 'gamma': 0.0001, 'kernel': 'rbf'}
train_acc for fold0=0.9632237871674492
test_acc for fold0=0.8515625
best params:{'C': 0.1, 'degree': 2, 'gamma': 1, 'kernel': 'poly'}
train_acc for fold1=1.0
test_acc for fold1=0.9921752738654147
best params:{'C': 1000, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}
train_acc for fold2=0.9996089166992569
test_acc for fold2=0.9843505477308294
best params:{'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}
train_acc for fold3=0.9992178333985139
test_acc for fold3=0.9483568075117371
best params:{'C': 1000, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}
train_acc for fold4=0.9996089166992569
test_acc for fold4=0.9640062597809077
train_accs: [0.9632237871674492, 1.0, 0.9996089166992569, 0.9992178333985139, 0.9996089166992569] 0.9923318907928953
test_accs: [0.8515625, 0.9921752738654147, 0.9843505477308294, 0.9483568075117371, 0.9640062597809077] 0.9480902777777777
